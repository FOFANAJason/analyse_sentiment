{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0d409-7a72-4529-bca6-913aaa56587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium_stealth import stealth\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bebb0-4701-4c34-84f2-1751289419b3",
   "metadata": {},
   "source": [
    "# SCRAPING TRIPADVISOR\n",
    "## Installation des dépendances\n",
    "- !pip install selenium\n",
    "- !pip install selenium-stealth\n",
    "- pip install fake-useragent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54a908-0b2d-4ba6-b7fb-b74f591bc3ea",
   "metadata": {},
   "source": [
    "<img src=\"scraping.png\" width=\"800\" height=\"200\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755a5f9b-87c4-4e21-8fcd-07692db13344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurer_driver():\n",
    "    \"\"\"\n",
    "    Configure et retourne un driver Selenium avec options de furtivité\n",
    "    pour éviter la détection en tant que bot\n",
    "    \"\"\"\n",
    "    options = Options()\n",
    "\n",
    "    # Désactivation des flags automation\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    # Désactivation des fonctionnalités de détection d'automatisation\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--disable-blink-features\")\n",
    "    options.add_argument(\"--no-sandbox\")  # Mode sans sandbox\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")  # Évite les problèmes de mémoire\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--disable-extensions\")  # Désactivation des extensions\n",
    "    \n",
    "    \n",
    "    # User-agent aléatoire\n",
    "    # ua = UserAgent()\n",
    "    # user_agent = ua.random\n",
    "    # options.add_argument(f'--user-agent={user_agent}')\n",
    "\n",
    "    # Autres paramètres\n",
    "    # options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--start-maximized\") # Fenêtre maximisée\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Masquer WebDriver\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    # Configuration de la furtivité pour ressembler à un navigateur humain\n",
    "    stealth(driver,\n",
    "            languages=[\"fr-FR\", \"fr\"],  # Langues françaises\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL\",\n",
    "            fix_hairline=True,  # Correction des lignes fines\n",
    "            run_on_insecure_origins=True,\n",
    "    )\n",
    "\n",
    "    # Timeouts réalistes\n",
    "    driver.set_page_load_timeout(30)\n",
    "    driver.set_script_timeout(20)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d598f7d-b3e7-4989-9785-f29c398bf7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comportement_humain(driver):\n",
    "    \"\"\"\n",
    "    Simule un comportement de navigation humain\n",
    "    \"\"\"\n",
    "    # Scroll aléatoire\n",
    "    scroll_height = random.randint(200, 600)\n",
    "    driver.execute_script(f\"window.scrollTo(0, {scroll_height});\")\n",
    "    \n",
    "    # Pause humaine\n",
    "    time.sleep(random.uniform(1.0, 3.0))\n",
    "    \n",
    "    # Mouvement de souris aléatoire\n",
    "    # actions = webdriver.ActionChains(driver)\n",
    "    # actions.move_by_offset(random.randint(10, 100), random.randint(10, 100))\n",
    "    # actions.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131a689a-d4e1-425b-a3d9-48bc9489fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraire_avis(driver, url_offre):\n",
    "    \"\"\"\n",
    "    Extrait tous les avis disponibles pour une offre donnée\n",
    "    \n",
    "    Args:\n",
    "        driver: Instance du driver Selenium\n",
    "        url_offre: URL de l'offre Tripadvisor\n",
    "    \n",
    "    Returns:\n",
    "        Liste des avis collectés\n",
    "    \"\"\"\n",
    "    print(f\"Début extraction: {url_offre}\")\n",
    "    \n",
    "    avis_collectes = []\n",
    "    page_actuelle = 0\n",
    "    url_page_courante = url_offre\n",
    "    pages_sans_nouveaux_avis = 0\n",
    "    pages_max = 4\n",
    "    \n",
    "    try:\n",
    "        # Parcours des pages d'avis jusqu'à 3 pages sans nouveaux avis\n",
    "        while pages_sans_nouveaux_avis < 3 and page_actuelle < pages_max:\n",
    "            page_actuelle += 1\n",
    "            \n",
    "            # Chargement avec timeout court\n",
    "            driver.set_page_load_timeout(25)\n",
    "            driver.get(url_page_courante)\n",
    "            \n",
    "            # Comportement humain aléatoire\n",
    "            temps_attente = random.uniform(3, 7)\n",
    "            time.sleep(temps_attente)\n",
    "\n",
    "            # Scroll humain\n",
    "            comportement_humain(driver)\n",
    "            \n",
    "            # Analyse du contenu HTML\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            avis_page = analyser_avis(soup, url_offre)\n",
    "            \n",
    "            # Filtrage des doublons et ajout des nouveaux avis\n",
    "            avis_avant = len(avis_collectes)\n",
    "            for avis in avis_page:\n",
    "                texte_avis = avis.get('texte_avis', '')\n",
    "                if texte_avis and not any(a.get('texte_avis') == texte_avis for a in avis_collectes):\n",
    "                    avis_collectes.append(avis)\n",
    "            \n",
    "            nouveaux_avis = len(avis_collectes) - avis_avant\n",
    "            \n",
    "            print(f\"   Page {page_actuelle}: {nouveaux_avis} nouveaux avis ({len(avis_collectes)} total)\")\n",
    "            \n",
    "            # Vérification si nouveaux avis\n",
    "            if nouveaux_avis == 0:\n",
    "                pages_sans_nouveaux_avis += 1\n",
    "                print(f\"   Aucun nouvel avis ({pages_sans_nouveaux_avis}/2)\")\n",
    "            else:\n",
    "                pages_sans_nouveaux_avis = 0\n",
    "\n",
    "            # Vérification si on a atteint la limite de pages\n",
    "            if page_actuelle >= pages_max:\n",
    "                print(f\"   Limite de {pages_max} pages atteinte\")\n",
    "                break\n",
    "            \n",
    "            # Recherche page suivante avec pause\n",
    "            url_page_suivante = trouver_page_suivante(soup, url_page_courante)\n",
    "            \n",
    "            if not url_page_suivante or url_page_suivante == url_page_courante:\n",
    "                print(f\"   Plus de pages disponibles\")\n",
    "                break\n",
    "                \n",
    "            url_page_courante = url_page_suivante\n",
    "\n",
    "            # Pause stratégique entre pages\n",
    "            if page_actuelle % 3 == 0:\n",
    "                time.sleep(random.uniform(8, 15))  # Longue pause occasionnelle\n",
    "            else:\n",
    "                time.sleep(random.uniform(2, 5))   # Courte pause normale\n",
    "            \n",
    "        print(f\"Extraction terminée: {len(avis_collectes)} avis collectés sur {page_actuelle} pages\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction: {str(e)}\")\n",
    "        print(f\"Avis récupérés avant l'erreur: {len(avis_collectes)}\")\n",
    "    \n",
    "    return avis_collectes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00fa9ef-9592-4dbb-871a-4a6af934fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyser_avis(soup, url_offre):\n",
    "    \"\"\"\n",
    "    Analyse le HTML et extrait les données des avis\n",
    "    \n",
    "    Args:\n",
    "        soup: Objet BeautifulSoup de la page\n",
    "        url_offre: URL de l'offre pour référence\n",
    "    \n",
    "    Returns:\n",
    "        Liste des avis parsés\n",
    "    \"\"\"\n",
    "    avis = []\n",
    "    \n",
    "    # Recherche de tous les conteneurs d'avis\n",
    "    conteneurs_avis = soup.find_all('div', attrs={'data-automation': 'reviewCard'})\n",
    "    \n",
    "    for conteneur in conteneurs_avis:\n",
    "        try:\n",
    "            donnees_avis = extraire_details_avis(conteneur, url_offre)\n",
    "            if donnees_avis and donnees_avis.get('texte_avis'):\n",
    "                avis.append(donnees_avis)\n",
    "        except Exception as e:\n",
    "            print(f\"   Erreur sur un avis: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c77fab-7dc7-4d1d-9454-3b741068466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraire_details_avis(conteneur, url_offre):\n",
    "    \"\"\"\n",
    "    Extrait les détails spécifiques d'un avis depuis son conteneur HTML\n",
    "    \n",
    "    Args:\n",
    "        conteneur: Élément HTML contenant un avis\n",
    "        url_offre: URL de l'offre pour référence\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire avec tous les détails de l'avis\n",
    "    \"\"\"\n",
    "    avis = {\n",
    "        'url_offre': url_offre,\n",
    "        'titre_offre': '',\n",
    "        'titre_avis': '',\n",
    "        'texte_avis': '',\n",
    "        'note_avis': '',\n",
    "        'date_avis': '',\n",
    "        'auteur_avis': '',\n",
    "        'localisation_auteur': '',\n",
    "        'contributions_auteur': '',\n",
    "        'type_voyage': '',\n",
    "        'votes_utiles': '0'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Titre de l'avis\n",
    "        element_titre = conteneur.find('span', class_='yCeTE')\n",
    "        if element_titre:\n",
    "            avis['titre_avis'] = element_titre.get_text(strip=True)\n",
    "        \n",
    "        # Texte de l'avis\n",
    "        element_texte = conteneur.find('div', class_='biGQs _P VImYz AWdfh')\n",
    "        if element_texte:\n",
    "            span_texte = element_texte.find('span', class_='yCeTE')\n",
    "            if span_texte:\n",
    "                avis['texte_avis'] = span_texte.get_text(strip=True)\n",
    "        \n",
    "        # Note de l'avis\n",
    "        element_note = conteneur.find('svg', class_='evwcZ')\n",
    "        if element_note:\n",
    "            titre_note = element_note.find('title')\n",
    "            if titre_note:\n",
    "                texte_note = titre_note.get_text(strip=True)\n",
    "                # Extraction du chiffre de la note (ex: \"5 sur 5 bulles\" -> 5)\n",
    "                correspondance = re.search(r'(\\d+)\\s+sur\\s+5', texte_note)\n",
    "                if correspondance:\n",
    "                    avis['note_avis'] = correspondance.group(1)\n",
    "        \n",
    "        # Date de l'avis\n",
    "        element_date = conteneur.find('div', class_='biGQs', string=re.compile(r'Écrit le'))\n",
    "        if element_date:\n",
    "            avis['date_avis'] = element_date.get_text(strip=True).replace('Écrit le ', '')\n",
    "        \n",
    "        # Auteur de l'avis\n",
    "        element_auteur = conteneur.find('span', class_='biGQs _P ezezH')\n",
    "        if element_auteur:\n",
    "            avis['auteur_avis'] = element_auteur.get_text(strip=True)\n",
    "        \n",
    "        # Localisation et contributions de l'auteur\n",
    "        element_localisation = conteneur.find('div', class_='vYLts')\n",
    "        if element_localisation:\n",
    "            texte_localisation = element_localisation.get_text(strip=True)\n",
    "            # Séparation localisation et contributions\n",
    "            parties = texte_localisation.split('•')\n",
    "            if len(parties) > 0:\n",
    "                avis['localisation_auteur'] = parties[0].strip()\n",
    "            if len(parties) > 1:\n",
    "                avis['contributions_auteur'] = parties[1].strip()\n",
    "        \n",
    "        # Type de voyage\n",
    "        element_voyage = conteneur.find('div', class_='RpeCd')\n",
    "        if element_voyage:\n",
    "            avis['type_voyage'] = element_voyage.get_text(strip=True)\n",
    "        \n",
    "        # Votes utiles\n",
    "        element_votes = conteneur.find('span', class_='kLqdM')\n",
    "        if element_votes:\n",
    "            avis['votes_utiles'] = element_votes.get_text(strip=True)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"      Détail manquant dans un avis: {str(e)}\")\n",
    "    \n",
    "    return avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d176dfe-f33e-46be-8138-a1e29652410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trouver_page_suivante(soup, url_actuelle):\n",
    "    \"\"\"\n",
    "    Trouve le lien vers la page suivante dans la pagination\n",
    "    \n",
    "    Args:\n",
    "        soup: Objet BeautifulSoup de la page actuelle\n",
    "        url_actuelle: URL de la page courante\n",
    "    \n",
    "    Returns:\n",
    "        URL de la page suivante ou None si non trouvée\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Recherche par aria-label \"Page suivante\"\n",
    "        lien_suivant = soup.find('a', attrs={'aria-label': 'Page suivante'})\n",
    "        if lien_suivant and lien_suivant.get('href'):\n",
    "            return urljoin(\"https://www.tripadvisor.fr\", lien_suivant['href'])\n",
    "        \n",
    "        # Recherche alternative dans la pagination\n",
    "        pagination = soup.find('div', class_='GMYGA')\n",
    "        if pagination:\n",
    "            liens = pagination.find_all('a', href=True)\n",
    "            for lien in liens:\n",
    "                if 'next' in lien.get('href', '') or 'or' in lien.get('href', ''):\n",
    "                    return urljoin(\"https://www.tripadvisor.fr\", lien['href'])\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"   Erreur recherche page suivante: {str(e)}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2383bf-20da-49f8-b43f-28786db7c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de l'extraction des avis Tripadvisor...\n",
      "Recherche des offres sur la page d'accueil...\n",
      "20 offres trouvées\n",
      "\n",
      "Traitement de l'offre 1/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g187147-d15040216-Eiffel_Tower_Guided_Tour_by_Elevator_with_Optional_Summit-Paris_Ile_de_France.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 40 avis collectés\n",
      "\n",
      "Traitement de l'offre 2/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g187895-d14917017-Leonardo_Da_Vinci_Museum_Entrance_Ticket-Florence_Tuscany.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 80 avis collectés\n",
      "\n",
      "Traitement de l'offre 3/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g188590-d15209893-Amsterdam_Classic_Saloon_Boat_Cruise_with_Drinks_and_Cheese-Amsterdam_North_Hollan.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 120 avis collectés\n",
      "\n",
      "Traitement de l'offre 4/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g189112-d17646451-Dolphins_Search_and_Benagil_Caves_from_Albufeira-Albufeira_Faro_District_Algarve.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 160 avis collectés\n",
      "\n",
      "Traitement de l'offre 5/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g274887-d23953331-Budapest_Unlimited_Prosecco_Beer_Aperol_Spritz_Cruise-Budapest_Central_Hungary.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 200 avis collectés\n",
      "\n",
      "Traitement de l'offre 6/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g190320-d20293604-Blue_Lagoon_Beaches_and_Bays_Catamaran_Sailing_Tour-Island_of_Malta.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 240 avis collectés\n",
      "\n",
      "Traitement de l'offre 7/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g187441-d14174261-Skip_The_Line_Alhambra_and_Generalife_Guided_Tour-Granada_Province_of_Granada_Anda.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 280 avis collectés\n",
      "\n",
      "Traitement de l'offre 8/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g274887-d11991250-Budapest_Danube_River_Sightseeing_Night_Cruise_with_Drinks-Budapest_Central_Hungar.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 320 avis collectés\n",
      "\n",
      "Traitement de l'offre 9/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g293734-d11989887-Atlas_Mountains_and_3_Valleys_Waterfalls_Camel_Ride_Marrakech-Marrakech_Marrakech_.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 360 avis collectés\n",
      "\n",
      "Traitement de l'offre 10/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g293734-d15845614-3_Days_Desert_Tour_From_Marrakech_To_Merzouga_Dunes_Camel_Trek-Marrakech_Marrakech.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 400 avis collectés\n",
      "\n",
      "Traitement de l'offre 11/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g188590-d15531329-Amsterdam_Light_Festival_Canal_Cruise_With_Unlimited_Drinks-Amsterdam_North_Hollan.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 440 avis collectés\n",
      "\n",
      "Traitement de l'offre 12/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g60763-d11460261-Dyker_Heights_Brooklyn_Christmas_Lights_Tour-New_York_City_New_York.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 480 avis collectés\n",
      "\n",
      "Traitement de l'offre 13/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g35805-d11448847-Chicago_Style_Holiday_Hike_Festive_Food_and_Walking_Tour-Chicago_Illinois.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 7 nouveaux avis (27 total)\n",
      "   Page 4: 0 nouveaux avis (27 total)\n",
      "   Aucun nouvel avis (1/2)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 27 avis collectés sur 4 pages\n",
      "Total actuel: 507 avis collectés\n",
      "\n",
      "Traitement de l'offre 14/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g186605-d27144746-Merry_Ploughboys_Irish_Night_Dublin_Admission_Ticket-Dublin_County_Dublin.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 2 nouveaux avis (32 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 32 avis collectés sur 4 pages\n",
      "Total actuel: 539 avis collectés\n",
      "\n",
      "Traitement de l'offre 15/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g190454-d11992210-Christmas_and_New_Year_Concert_at_St_Peter_s_Church_in_Vienna-Vienna.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Plus de pages disponibles\n",
      "Extraction terminée: 20 avis collectés sur 2 pages\n",
      "Total actuel: 559 avis collectés\n",
      "\n",
      "Traitement de l'offre 16/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g189922-d23660722-Meet_Santa_Claus_Santa_s_Reindeer_Ride_Greet_Huskies-Rovaniemi_Lapland.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 3 nouveaux avis (23 total)\n",
      "   Page 4: 0 nouveaux avis (23 total)\n",
      "   Aucun nouvel avis (1/2)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 23 avis collectés sur 4 pages\n",
      "Total actuel: 582 avis collectés\n",
      "\n",
      "Traitement de l'offre 17/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g189158-d11890033-Lisbon_Fireworks_Music_and_Open_Bar_in_New_Year_s_Eve_Cruise-Lisbon_Lisbon_Distric.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 5 nouveaux avis (15 total)\n",
      "   Page 3: 0 nouveaux avis (15 total)\n",
      "   Aucun nouvel avis (1/2)\n",
      "   Page 4: 0 nouveaux avis (15 total)\n",
      "   Aucun nouvel avis (2/2)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 15 avis collectés sur 4 pages\n",
      "Total actuel: 597 avis collectés\n",
      "\n",
      "Traitement de l'offre 18/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g186338-d20926219-London_by_Night_Bus_Tour_with_Christmas_Lights_and_Live_Guide-London_England.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 10 nouveaux avis (20 total)\n",
      "   Page 3: 10 nouveaux avis (30 total)\n",
      "   Page 4: 10 nouveaux avis (40 total)\n",
      "   Limite de 4 pages atteinte\n",
      "Extraction terminée: 40 avis collectés sur 4 pages\n",
      "Total actuel: 637 avis collectés\n",
      "\n",
      "Traitement de l'offre 19/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g187791-d14986408-Celebrate_Christmas_in_Rome_Small_Group_Walking_Tour-Rome_Lazio.html\n",
      "   Page 1: 10 nouveaux avis (10 total)\n",
      "   Page 2: 1 nouveaux avis (11 total)\n",
      "   Plus de pages disponibles\n",
      "Extraction terminée: 11 avis collectés sur 2 pages\n",
      "Total actuel: 648 avis collectés\n",
      "\n",
      "Traitement de l'offre 20/20\n",
      "Début extraction: https://www.tripadvisor.fr/AttractionProductReview-g60713-d11477759-Holiday_Lights_Tour_of_San_Francisco-San_Francisco_California.html\n",
      "   Page 1: 9 nouveaux avis (9 total)\n",
      "   Plus de pages disponibles\n",
      "Extraction terminée: 9 avis collectés sur 1 pages\n",
      "Total actuel: 657 avis collectés\n",
      "\n",
      "SUCCÈS: 657 avis sauvegardés dans 'tripadvisor_avis.csv'\n",
      "\n",
      "Aperçu des données:\n",
      "Colonnes: ['url_offre', 'titre_offre', 'titre_avis', 'texte_avis', 'note_avis', 'date_avis', 'auteur_avis', 'localisation_auteur', 'contributions_auteur', 'type_voyage', 'votes_utiles']\n",
      "\n",
      "Exemple d'avis:\n",
      "  1. [5/5] Ana était charmante, joyeuse et a raconté des faits intéressants.Merci. . . . . . . . . . . . . . . ...\n",
      "  2. [5/5] La Tour Eiffel a été absolument mémorable ! Notre guide, Ana Bauk, a donné vie à l’histoire de la to...\n",
      "\n",
      "Extraction terminée\n"
     ]
    }
   ],
   "source": [
    "def extraire_titre_offre(soup):\n",
    "    \"\"\"\n",
    "    Extrait le titre de l'offre depuis la page\n",
    "    \n",
    "    Args:\n",
    "        soup: Objet BeautifulSoup de la page\n",
    "    \n",
    "    Returns:\n",
    "        Titre de l'offre ou chaîne vide si non trouvé\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Plusieurs sélecteurs possibles pour le titre de l'offre\n",
    "        selecteurs_titre = [\n",
    "            'h1[data-automation=\"mainH1\"]',\n",
    "            'h1.HjBfq',\n",
    "            '.kUaMB',\n",
    "            'h1'\n",
    "        ]\n",
    "        \n",
    "        for selecteur in selecteurs_titre:\n",
    "            element_titre = soup.select_one(selecteur)\n",
    "            if element_titre:\n",
    "                titre = element_titre.get_text(strip=True)\n",
    "                if titre and len(titre) > 0:\n",
    "                    return titre\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   Erreur extraction titre offre: {str(e)}\")\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def obtenir_liens_offres_accueil(driver):\n",
    "    \"\"\"\n",
    "    Récupère les liens des offres depuis la page d'accueil de Tripadvisor\n",
    "    \n",
    "    Args:\n",
    "        driver: Instance du driver Selenium\n",
    "    \n",
    "    Returns:\n",
    "        Liste des URLs des offres trouvées\n",
    "    \"\"\"\n",
    "    print(\"Recherche des offres sur la page d'accueil...\")\n",
    "    \n",
    "    driver.get(\"https://www.tripadvisor.fr/\")\n",
    "    time.sleep(6)  # Pause pour chargement complet\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    liens_offres = []\n",
    "    \n",
    "    # Patterns de recherche pour les liens d'offres\n",
    "    patterns_liens = [\n",
    "        'a[href*=\"/AttractionProductReview-\"]',\n",
    "        'a[href*=\"/ActivityProductReview-\"]',\n",
    "        'a[href*=\"/TourProductReview-\"]'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns_liens:\n",
    "        liens = soup.select(pattern)\n",
    "        for lien in liens:\n",
    "            href = lien.get('href')\n",
    "            if href and not href.startswith('http'):\n",
    "                url_complete = urljoin(\"https://www.tripadvisor.fr\", href)\n",
    "                if url_complete not in liens_offres:\n",
    "                    liens_offres.append(url_complete)\n",
    "    \n",
    "    print(f\"{len(liens_offres)} offres trouvées\")\n",
    "    return liens_offres #[:15]  # Limite à 15 offres pour les tests\n",
    "\n",
    "\n",
    "def principal():\n",
    "    \"\"\"\n",
    "    Fonction principale orchestrant l'extraction des avis Tripadvisor\n",
    "    \"\"\"\n",
    "    driver = configurer_driver()\n",
    "    tous_avis = []\n",
    "    \n",
    "    try:\n",
    "        # Récupération des liens d'offres depuis l'accueil\n",
    "        liens_offres = obtenir_liens_offres_accueil(driver)\n",
    "        \n",
    "        # Extraction des avis pour chaque offre\n",
    "        for i, url_offre in enumerate(liens_offres, 1):\n",
    "            print(f\"\\nTraitement de l'offre {i}/{len(liens_offres)}\")\n",
    "            \n",
    "            # Extraction du titre de l'offre\n",
    "            driver.get(url_offre)\n",
    "            time.sleep(3)\n",
    "            soup_offre = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            titre_offre = extraire_titre_offre(soup_offre)\n",
    "            \n",
    "            # Extraction des avis avec le titre de l'offre\n",
    "            avis = extraire_avis(driver, url_offre)\n",
    "            \n",
    "            # Ajout du titre de l'offre à chaque avis\n",
    "            for avi in avis:\n",
    "                avi['titre_offre'] = titre_offre\n",
    "            \n",
    "            tous_avis.extend(avis)\n",
    "            \n",
    "            print(f\"Total actuel: {len(tous_avis)} avis collectés\")\n",
    "            \n",
    "            # Pause entre les offres pour éviter le blocage\n",
    "            if i < len(liens_offres):\n",
    "                time.sleep(3)\n",
    "        \n",
    "        # Sauvegarde des données\n",
    "        if tous_avis:\n",
    "            df = pd.DataFrame(tous_avis)\n",
    "            \n",
    "            # Nettoyage des données\n",
    "            df = df.drop_duplicates(subset=['texte_avis'], keep='first')\n",
    "            df = df[df['texte_avis'].str.len() > 5]  # Suppression des avis trop courts\n",
    "            \n",
    "            # Sauvegarde en CSV\n",
    "            nom_fichier = './DATA/tripadvisor_avis.csv'\n",
    "            df.to_csv(nom_fichier, index=False, encoding='utf-8-sig', sep=';')\n",
    "            \n",
    "            print(f\"\\nSUCCÈS: {len(df)} avis sauvegardés dans '{nom_fichier}'\")\n",
    "            \n",
    "            # Aperçu des données\n",
    "            print(\"\\nAperçu des données:\")\n",
    "            print(f\"Colonnes: {df.columns.tolist()}\")\n",
    "            print(f\"\\nExemple d'avis:\")\n",
    "            for i, ligne in df.head(2).iterrows():\n",
    "                print(f\"  {i+1}. [{ligne['note_avis']}/5] {ligne['texte_avis'][:100]}...\")\n",
    "                \n",
    "        else:\n",
    "            print(\"Aucun avis extrait\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur générale: {str(e)}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"\\nExtraction terminée\")\n",
    "\n",
    "\n",
    "# Démarrage du script\n",
    "print(\"Démarrage de l'extraction des avis Tripadvisor...\")\n",
    "principal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb9b45-c56c-437e-80d1-037dbb5f4b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf2f62-59c1-4d2c-a217-7740171fb11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
